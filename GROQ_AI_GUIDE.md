# ü§ñ Groq AI Integration Guide

## Overview

DSA Sync now uses **Groq AI** with **Llama 3.3 70B** and **Llama 3.1 8B** models for intelligent features. All AI functionality has been migrated from OpenAI to Groq for faster, cost-effective responses.

## ‚úÖ Setup Complete

### Configuration
- ‚úÖ Groq API Key configured in `.env.local`
- ‚úÖ AI Provider set to `groq`
- ‚úÖ `groq-sdk` package installed
- ‚úÖ All 6 AI features implemented

### API Key
```env
GROQ_API_KEY=gsk-your-groq-api-key-here
AI_PROVIDER=groq
```

---

## üöÄ AI Features & API Endpoints

### 1Ô∏è‚É£ Weekly Growth Report
**Model:** `llama-3.3-70b-versatile` (70B for complex analysis)

**Endpoint:** `GET /api/ai/weekly-report`

**Description:** Generates a comprehensive weekly analysis of your DSA progress with actionable insights.

**Response Format:**
```json
{
  "success": true,
  "report": {
    "summary": "Completed 18 problems this week...",
    "strengths": ["Strong in DP", "Consistent streak"],
    "weakAreas": ["Graph algorithms", "Time management"],
    "improvementTrend": "Improving steadily with 50% increase",
    "nextWeekFocus": ["Focus on Graph problems", "Practice BFS/DFS"],
    "motivationalNote": "Great progress! Keep it up!"
  }
}
```

**Usage:**
```typescript
const response = await fetch('/api/ai/weekly-report', {
  headers: { Authorization: `Bearer ${token}` }
});
const data = await response.json();
```

---

### 2Ô∏è‚É£ Smart Recommendation
**Model:** `llama-3.1-8b-instant` (8B for quick responses)

**Endpoint:** `GET /api/ai/smart-recommendation`

**Description:** Analyzes your weak topics and provides focused practice strategy.

**Response Format:**
```json
{
  "success": true,
  "recommendation": {
    "recommendedTopics": ["Graph", "Backtracking"],
    "difficultySuggestion": "Focus on Medium problems for 2 weeks",
    "practicePlan": "Solve 3 Graph problems daily for next 5 days",
    "revisionAdvice": "Complete 5 pending revisions before new topics"
  },
  "stats": {
    "weakTopics": ["Graph", "Backtracking"],
    "noHardSolvedInDays": 14,
    "revisionPending": 5,
    "avgTime": 40
  }
}
```

**Usage:**
```typescript
const response = await fetch('/api/ai/smart-recommendation', {
  headers: { Authorization: `Bearer ${token}` }
});
```

---

### 3Ô∏è‚É£ Solution Comparison
**Model:** `llama-3.3-70b-versatile` (70B for detailed comparison)

**Endpoint:** `POST /api/ai/compare`

**Description:** Compares two users' approaches to the same problem and suggests hybrid solutions.

**Request Body:**
```json
{
  "problemId": "problem_id_here",
  "friendId": "friend_user_id"
}
```

**Response Format:**
```json
{
  "success": true,
  "comparison": {
    "betterApproach": "User B's prefix sum approach is more efficient",
    "efficiencyComparison": "O(n¬≤) vs O(n) time complexity",
    "learningInsight": "Hashmap optimization reduces nested loops",
    "suggestedHybridIdea": "Use prefix sum with sliding window"
  }
}
```

---

### 4Ô∏è‚É£ Pattern Detection
**Model:** `llama-3.3-70b-versatile` (70B for deep analysis)

**Endpoint:** `GET /api/ai/pattern-detection`

**Description:** Analyzes 50+ problems to detect solving patterns and personality.

**Response Format:**
```json
{
  "success": true,
  "patterns": {
    "solvingPersonality": "Fast solver with pattern-matching skills",
    "majorPatterns": [
      "Prefers iterative over recursive",
      "Strong in array manipulation"
    ],
    "riskAreas": [
      "Rushing through edge cases",
      "Weak in graph traversal"
    ],
    "interviewReadinessLevel": "Mid-level (60%)",
    "strategicAdvice": "Focus on graph problems and practice edge case thinking"
  }
}
```

---

### 5Ô∏è‚É£ Daily Reflection Generator
**Model:** `llama-3.1-8b-instant` (8B for quick feedback)

**Endpoint:** `GET /api/ai/reflection`

**Description:** Generates a concise reflection based on today's problem-solving activity.

**Response Format:**
```json
{
  "success": true,
  "reflection": {
    "reflection": "Today you practiced Tree and DFS problems. Good focus!",
    "keyTakeaway": "Null pointer handling is your weak spot",
    "improvementTip": "Before coding, draw the tree and trace edge cases"
  },
  "problemsCount": 3
}
```

**POST with specific date:**
```json
{
  "date": "2026-02-20"
}
```

---

### 6Ô∏è‚É£ Challenge Generator
**Model:** `llama-3.1-8b-instant` (8B for quick planning)

**Endpoint:** `POST /api/ai/challenge`

**Description:** Creates collaborative challenges between two friends.

**Request Body:**
```json
{
  "friendUsername": "john_doe"
}
```

**Response Format:**
```json
{
  "success": true,
  "challenge": {
    "challengeTitle": "Graph & Greedy 7-Day Sprint",
    "duration": "7 days",
    "focusTopics": ["Graph", "Greedy"],
    "dailyGoal": "Solve 2 problems per day (1 Graph, 1 Greedy)",
    "successCriteria": "Complete 14 problems with 80% first-attempt success"
  },
  "participants": {
    "user": "current_user",
    "friend": "john_doe"
  }
}
```

---

## üéØ Model Usage Strategy

| Feature | Model | Reason |
|---------|-------|--------|
| Weekly Report | 70B | Complex multi-faceted analysis |
| Solution Compare | 70B | Deep code comparison |
| Pattern Detection | 70B | Long-term behavioral analysis |
| Recommendation | 8B | Quick personalized suggestions |
| Reflection | 8B | Fast daily feedback |
| Challenge | 8B | Simple planning logic |

---

## üîß Technical Details

### Core Function
```typescript
import { generateAIResponse } from '@/lib/ai-service';

const response = await generateAIResponse({
  systemPrompt: 'You are a DSA mentor...',
  userPrompt: `User stats: ${JSON.stringify(stats)}`,
  model: 'llama-3.3-70b-versatile', // or 'llama-3.1-8b-instant'
  temperature: 0.3, // Lower = more focused
  maxTokens: 2048,
});
```

### Response Handling
```typescript
if (response.success) {
  console.log(response.data); // Parsed JSON
} else {
  console.error(response.error);
}
```

---

## üí° Pro Tips

1. **Temperature Setting:**
   - Use `0.3` for structured outputs (all features)
   - Lower temperature = more consistent JSON

2. **Max Tokens:**
   - 2048 is sufficient for all features
   - Limits cost and response time

3. **Caching:**
   - Cache AI responses in database
   - Avoid regenerating same analysis

4. **Error Handling:**
   - Always check `response.success`
   - Handle Groq API rate limits gracefully

5. **Validation:**
   - All responses are JSON validated
   - Parse with `JSON.parse()` for safety

---

## üîÑ Migration from OpenAI

**What Changed:**
- ‚ùå Removed: OpenAI SDK
- ‚úÖ Added: Groq SDK (`groq-sdk`)
- ‚úÖ Updated: All AI functions use Groq
- ‚úÖ Backward Compatible: Same interfaces

**No Breaking Changes:**
- Existing API routes work as-is
- Same response formats
- Drop-in replacement

---

## üìä Performance Benefits

| Metric | OpenAI | Groq |
|--------|--------|------|
| Speed | ~3-5s | ~0.5-1s |
| Cost | $0.01/req | $0.001/req |
| Model | GPT-4 | Llama 3.3 70B |
| Quality | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |

---

## üß™ Testing

### Test Weekly Report
```bash
curl -X GET http://localhost:3000/api/ai/weekly-report \
  -H "Authorization: Bearer YOUR_TOKEN"
```

### Test Smart Recommendation
```bash
curl -X GET http://localhost:3000/api/ai/smart-recommendation \
  -H "Authorization: Bearer YOUR_TOKEN"
```

### Test Reflection
```bash
curl -X GET http://localhost:3000/api/ai/reflection \
  -H "Authorization: Bearer YOUR_TOKEN"
```

### Test Challenge
```bash
curl -X POST http://localhost:3000/api/ai/challenge \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"friendUsername": "friend_username"}'
```

---

## ‚ö†Ô∏è Important Notes

1. **Minimum Data Requirements:**
   - Weekly Report: At least 5 problems solved this week
   - Pattern Detection: At least 50 problems total
   - Smart Recommendation: At least 5 problems
   - Reflection: At least 1 problem today

2. **Rate Limits:**
   - Groq has generous free tier
   - 30 requests/minute typical limit
   - Implement retry logic

3. **Error Messages:**
   - "No problems solved" ‚Üí User needs to solve problems first
   - "AI service not configured" ‚Üí Check GROQ_API_KEY
   - "Failed to generate" ‚Üí Network/API issue

---

## üéÅ Bonus Features

### Helper Functions
```typescript
// Direct function calls (bypass API routes)
import {
  generateWeeklyGrowthReport,
  generateSmartRecommendation,
  generateSolutionComparison,
  generatePatternDetection,
  generateReflection,
  generateChallenge
} from '@/lib/ai-service';

// Example
const result = await generateWeeklyGrowthReport({
  totalSolved: 18,
  easy: 5,
  medium: 10,
  hard: 3,
  topicBreakdown: { Array: 6, DP: 4 },
  weakestTopic: 'Graph',
  avgTimeMinutes: 32,
  revisionPending: 4,
  streak: 7,
  lastWeekSolved: 12
});
```

---

## üöÄ Next Steps

1. ‚úÖ Groq API integrated
2. ‚úÖ All 6 features implemented
3. ‚úÖ API routes created
4. üîÑ Test each endpoint
5. üîÑ Integrate into UI components
6. üîÑ Add caching layer
7. üîÑ Monitor usage & costs

---

## üìö Resources

- [Groq Console](https://console.groq.com/)
- [Llama 3 Documentation](https://ai.meta.com/llama/)
- [API Reference](lib/ai-service.ts)

---

**All AI features are now powered by Groq! üéâ**
